{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, average_precision_score\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"../Datasets/X_train.csv\")\n",
    "y_train = pd.read_csv(\"../Datasets/y_train.csv\").values.ravel()\n",
    "\n",
    "X_val = pd.read_csv(\"../Datasets/X_val.csv\")\n",
    "y_val = pd.read_csv(\"../Datasets/y_val.csv\").values.ravel()\n",
    "\n",
    "X_test = pd.read_csv(\"../Datasets/X_test.csv\")\n",
    "y_test = pd.read_csv(\"../Datasets/y_test.csv\").values.ravel()\n",
    "\n",
    "X_train_resampled = pd.read_csv(\"../Datasets/X_train_resampled.csv\")\n",
    "y_train_resampled = pd.read_csv(\"../Datasets/y_train_resampled.csv\").values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Log-Transformed Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use SMOTE Resampled Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use original train with class weighting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Random Forest model \n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Grid Search hyperparameters \n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10],\n",
    "    'min_samples_split': [5],\n",
    "    'min_samples_leaf': [2],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,                # 3-fold cross-validation\n",
    "    scoring='roc_auc',  \n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    }
   ],
   "source": [
    "# Fit Grid Search \n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best CV ROC-AUC:\", grid_search.best_score_)\n",
    "\n",
    "# Use best model \n",
    "best_rf = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Validation Performance ===\n",
      "Precision (macro): 0.5484\n",
      "Recall (macro): 0.6878\n",
      "F1-score (macro): 0.5696\n",
      "ROC-AUC: 0.8608\n",
      "PR-AUC: 0.1188\n"
     ]
    }
   ],
   "source": [
    "# Predict on validation set \n",
    "y_pred = best_rf.predict(X_val)\n",
    "y_proba = best_rf.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Evaluation Metrics\n",
    "precision = precision_score(y_val, y_pred, average='macro')\n",
    "recall = recall_score(y_val, y_pred, average='macro')\n",
    "f1 = f1_score(y_val, y_pred, average='macro')\n",
    "roc_auc = roc_auc_score(y_val, y_proba)\n",
    "pr_auc = average_precision_score(y_val, y_proba)\n",
    "\n",
    "print(\"\\n=== Validation Performance ===\")\n",
    "print(f\"Precision (macro): {precision:.4f}\")\n",
    "print(f\"Recall (macro): {recall:.4f}\")\n",
    "print(f\"F1-score (macro): {f1:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "print(f\"PR-AUC: {pr_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest without SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Validation Performance ===\n",
      "Precision (macro): 0.4933\n",
      "Recall (macro): 0.5000\n",
      "F1-score (macro): 0.4966\n",
      "ROC-AUC: 0.8718\n",
      "PR-AUC: 0.1472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/natalie/bank-fraud-detection/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "best_params = {\n",
    "    'max_depth': 10,\n",
    "    'max_features': 'log2',\n",
    "    'min_samples_leaf': 2,\n",
    "    'min_samples_split': 5,\n",
    "    'n_estimators': 200,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "# Initialize and train the final Random Forest\n",
    "final_rf = RandomForestClassifier(**best_params)\n",
    "final_rf.fit(X_train, y_train)  # ravel() if y_train is a dataframe\n",
    "\n",
    "# Predictions\n",
    "y_val_pred = final_rf.predict(X_val)\n",
    "y_val_proba = final_rf.predict_proba(X_val)[:, 1]  # probability of class 1 (fraud)\n",
    "\n",
    "# Evaluation Metrics\n",
    "precision = precision_score(y_val, y_val_pred, average='macro')\n",
    "recall = recall_score(y_val, y_val_pred, average='macro')\n",
    "f1 = f1_score(y_val, y_val_pred, average='macro')\n",
    "roc_auc = roc_auc_score(y_val, y_val_proba)\n",
    "pr_auc = average_precision_score(y_val, y_val_proba)\n",
    "\n",
    "print(\"\\n=== Validation Performance ===\")\n",
    "print(f\"Precision (macro): {precision:.4f}\")\n",
    "print(f\"Recall (macro): {recall:.4f}\")\n",
    "print(f\"F1-score (macro): {f1:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "print(f\"PR-AUC: {pr_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optuna, log vs non-log"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
